{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2008381,
          "sourceType": "datasetVersion",
          "datasetId": 1201791
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "SAR image colorization (vgg19)",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devdandekar24/Perceptual-loss-vgg19/blob/main/perceptual%20vgg19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "requiemonk_sentinel12_image_pairs_segregated_by_terrain_path = kagglehub.dataset_download('requiemonk/sentinel12-image-pairs-segregated-by-terrain')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "3uP50SzQ_nXK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Imports and Setup\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage import io\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vgg19, VGG19_Weights\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils import spectral_norm\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:29.524979Z",
          "iopub.execute_input": "2025-04-03T09:23:29.525262Z",
          "iopub.status.idle": "2025-04-03T09:23:35.365413Z",
          "shell.execute_reply.started": "2025-04-03T09:23:29.525231Z",
          "shell.execute_reply": "2025-04-03T09:23:35.364421Z"
        },
        "trusted": true,
        "id": "YLMcf5Rj_nXM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data Loading and Preprocessing\n",
        "\n",
        "# Define the base directory of your dataset\n",
        "base_dir = \"/kaggle/input/sentinel12-image-pairs-segregated-by-terrain/v_2\"\n",
        "categories = ['agri', 'barrenland', 'grassland', 'urban']\n",
        "\n",
        "# Collect all pairs of input (SAR) and output (optical) image paths\n",
        "input_output_pairs = []\n",
        "for category in categories:\n",
        "    input_folder = os.path.join(base_dir, category, 's1')\n",
        "    output_folder = os.path.join(base_dir, category, 's2')\n",
        "\n",
        "    # Get all input and output image file paths\n",
        "    input_images = sorted(glob.glob(os.path.join(input_folder, \"*.png\")))\n",
        "    output_images = sorted(glob.glob(os.path.join(output_folder, \"*.png\")))\n",
        "\n",
        "    # Ensure that the number of images match\n",
        "    assert len(input_images) == len(output_images), \\\n",
        "        f\"Number of images in {input_folder} and {output_folder} do not match.\"\n",
        "\n",
        "    for input_img, output_img in zip(input_images, output_images):\n",
        "        input_output_pairs.append((input_img, output_img))\n",
        "\n",
        "# Checking the size of the dataset\n",
        "print(f\"Total dataset size: {len(input_output_pairs)}\")\n",
        "\n",
        "# Shuffle and split the dataset into training and validation sets\n",
        "np.random.seed(123)  # Seeding for reproducibility\n",
        "input_output_pairs = np.random.permutation(input_output_pairs)  # Shuffling the pairs\n",
        "\n",
        "# Splitting into training and validation sets\n",
        "train_ratio = 0.8\n",
        "num_total = len(input_output_pairs)\n",
        "num_train = int(train_ratio * num_total)\n",
        "\n",
        "train_pairs = input_output_pairs[:num_train]\n",
        "val_pairs = input_output_pairs[num_train:]\n",
        "\n",
        "print(f\"Training set size: {len(train_pairs)}\")\n",
        "print(f\"Validation set size: {len(val_pairs)}\")\n",
        "\n",
        "# Example: Accessing a pair\n",
        "example_input, example_output = train_pairs[0]\n",
        "print(\"Example input image path:\", example_input)\n",
        "print(\"Example output image path:\", example_output)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:35.367455Z",
          "iopub.execute_input": "2025-04-03T09:23:35.367836Z",
          "iopub.status.idle": "2025-04-03T09:23:39.090442Z",
          "shell.execute_reply.started": "2025-04-03T09:23:35.367807Z",
          "shell.execute_reply": "2025-04-03T09:23:39.089461Z"
        },
        "trusted": true,
        "id": "ygmkZVuZ_nXO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Utility Functions\n",
        "\n",
        "# AverageMeter for tracking losses\n",
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.count, self.avg, self.sum = [0.] * 3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += count * val\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "# Function to convert Lab to RGB\n",
        "def lab_to_rgb(L, ab):\n",
        "    L = (L + 1.) * 50.  # Denormalize L channel from [-1, 1] to [0, 100]\n",
        "    ab = ab * 110.  # Denormalize ab channels from [-1, 1] to [-110, 110]\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().detach().numpy()  # Shape: [batch_size, H, W, 3]\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img.astype('float64'))\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "# Visualization function\n",
        "def visualize(model, data, save=False, epoch=0):\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "    fake_color = model.fake_color.detach()\n",
        "    real_color = model.ab\n",
        "    L = model.L\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "        if i == 0:\n",
        "            ax.set_title('Input L (SAR)')\n",
        "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        if i == 0:\n",
        "            ax.set_title('Generated RGB')\n",
        "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        if i == 0:\n",
        "            ax.set_title('Ground Truth RGB')\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "        plt.savefig(f\"colorization_epoch_{epoch}.png\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.091815Z",
          "iopub.execute_input": "2025-04-03T09:23:39.092236Z",
          "iopub.status.idle": "2025-04-03T09:23:39.102918Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.092192Z",
          "shell.execute_reply": "2025-04-03T09:23:39.102067Z"
        },
        "trusted": true,
        "id": "J5YliNN1_nXP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Custom Dataset Class\n",
        "\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, pairs, split='train', transform=None):\n",
        "        self.pairs = pairs\n",
        "        self.split = split\n",
        "        self.size = 256  # Image size\n",
        "        self.transform = transform\n",
        "\n",
        "        # Define default transforms if none are provided\n",
        "        if self.transform is None:\n",
        "            if self.split == 'train':\n",
        "                self.transform = transforms.Compose([\n",
        "                    transforms.Resize((self.size, self.size), Image.BICUBIC),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                ])\n",
        "            else:\n",
        "                self.transform = transforms.Resize((self.size, self.size), Image.BICUBIC)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_path, output_path = self.pairs[idx]\n",
        "\n",
        "        # Load the input (SAR) image and convert to grayscale\n",
        "        input_img = Image.open(input_path).convert('L')  # Ensure it's grayscale\n",
        "        input_img = self.transform(input_img)\n",
        "        input_img = transforms.ToTensor()(input_img)  # Shape: [1, H, W]\n",
        "\n",
        "        # Load the output (optical) image and convert to RGB\n",
        "        output_img = Image.open(output_path).convert('RGB')\n",
        "        output_img = self.transform(output_img)\n",
        "        output_img = transforms.ToTensor()(output_img)  # Shape: [3, H, W]\n",
        "\n",
        "        # Convert output image from RGB to Lab color space\n",
        "        output_img_np = output_img.permute(1, 2, 0).numpy()  # Convert to HWC\n",
        "        output_lab = rgb2lab(output_img_np).astype('float32')\n",
        "        output_lab = transforms.ToTensor()(output_lab)  # Shape: [3, H, W]\n",
        "\n",
        "        # Normalize L and ab channels\n",
        "        L = input_img * 2.0 - 1.0  # Normalize L channel to [-1, 1]\n",
        "        ab = output_lab[1:, ...] / 110.  # Normalize ab channels to [-1, 1]\n",
        "\n",
        "        return {'L': L, 'ab': ab}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.104253Z",
          "iopub.execute_input": "2025-04-03T09:23:39.104526Z",
          "iopub.status.idle": "2025-04-03T09:23:39.134605Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.104499Z",
          "shell.execute_reply": "2025-04-03T09:23:39.133443Z"
        },
        "trusted": true,
        "id": "beRHtawv_nXQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Data Loaders\n",
        "\n",
        "def make_dataloaders(pairs, batch_size=8, num_workers=4, split='train'):\n",
        "    dataset = ColorizationDataset(pairs, split=split)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(split=='train'),\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 8  # Reduced batch size to fit in memory\n",
        "train_dl = make_dataloaders(train_pairs, batch_size=batch_size, num_workers=4, split='train')\n",
        "val_dl = make_dataloaders(val_pairs, batch_size=batch_size, num_workers=4, split='val')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.135702Z",
          "iopub.execute_input": "2025-04-03T09:23:39.135951Z",
          "iopub.status.idle": "2025-04-03T09:23:39.15111Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.135926Z",
          "shell.execute_reply": "2025-04-03T09:23:39.150169Z"
        },
        "trusted": true,
        "id": "-BFlTrtV_nXR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: UnetBlock without Self-Attention\n",
        "\n",
        "class UnetBlock(nn.Module):\n",
        "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
        "                 innermost=False, outermost=False):\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "        if input_c is None:\n",
        "            input_c = nf\n",
        "        downconv = nn.Conv2d(input_c, ni, kernel_size=4, stride=2,\n",
        "                             padding=1, bias=False)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(ni)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = nn.BatchNorm2d(nf)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2,\n",
        "                                        padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=False)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=False)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            if dropout:\n",
        "                up += [nn.Dropout(0.5)]\n",
        "            model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.152187Z",
          "iopub.execute_input": "2025-04-03T09:23:39.15247Z",
          "iopub.status.idle": "2025-04-03T09:23:39.166805Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.152443Z",
          "shell.execute_reply": "2025-04-03T09:23:39.165872Z"
        },
        "trusted": true,
        "id": "yplSxwj8_nXS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: U-Net Generator\n",
        "\n",
        "class UnetGenerator(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, num_downs=8, num_filters=64):\n",
        "        super().__init__()\n",
        "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
        "        for _ in range(num_downs - 5):\n",
        "            unet_block = UnetBlock(num_filters * 8, num_filters * 8,\n",
        "                                   submodule=unet_block, dropout=True)\n",
        "        unet_block = UnetBlock(num_filters * 4, num_filters * 8,\n",
        "                               submodule=unet_block)\n",
        "        unet_block = UnetBlock(num_filters * 2, num_filters * 4,\n",
        "                               submodule=unet_block)\n",
        "        unet_block = UnetBlock(num_filters, num_filters * 2,\n",
        "                               submodule=unet_block)\n",
        "        self.model = UnetBlock(output_c, num_filters, input_c=input_c,\n",
        "                               submodule=unet_block, outermost=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.169797Z",
          "iopub.execute_input": "2025-04-03T09:23:39.170134Z",
          "iopub.status.idle": "2025-04-03T09:23:39.18127Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.170104Z",
          "shell.execute_reply": "2025-04-03T09:23:39.180442Z"
        },
        "trusted": true,
        "id": "YJFQNgPC_nXT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Discriminator with Spectral Normalization\n",
        "\n",
        "class PatchDiscriminatorSN(nn.Module):\n",
        "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
        "        super().__init__()\n",
        "        layers = [self.get_layers(input_c, num_filters, norm=False)]\n",
        "        nf_mult = 1\n",
        "        for n in range(1, n_down):\n",
        "            nf_mult_prev = nf_mult\n",
        "            nf_mult = min(2 ** n, 8)\n",
        "            layers += [self.get_layers(num_filters * nf_mult_prev,\n",
        "                                       num_filters * nf_mult, s=2)]\n",
        "        nf_mult_prev = nf_mult\n",
        "        nf_mult = min(2 ** n_down, 8)\n",
        "        layers += [self.get_layers(num_filters * nf_mult_prev,\n",
        "                                   num_filters * nf_mult, s=1)]\n",
        "        layers += [spectral_norm(nn.Conv2d(num_filters * nf_mult, 1,\n",
        "                                           kernel_size=4, stride=1, padding=1))]\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def get_layers(self, in_c, out_c, k=4, s=2, p=1, norm=True):\n",
        "        layers = [spectral_norm(nn.Conv2d(in_c, out_c, kernel_size=k,\n",
        "                                          stride=s, padding=p))]\n",
        "        if norm:\n",
        "            layers.append(nn.BatchNorm2d(out_c))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.182399Z",
          "iopub.execute_input": "2025-04-03T09:23:39.182736Z",
          "iopub.status.idle": "2025-04-03T09:23:39.197028Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.182698Z",
          "shell.execute_reply": "2025-04-03T09:23:39.196354Z"
        },
        "trusted": true,
        "id": "q8erk_th_nXU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: GAN Loss\n",
        "\n",
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        labels = self.real_label if target_is_real else self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def forward(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.197948Z",
          "iopub.execute_input": "2025-04-03T09:23:39.198199Z",
          "iopub.status.idle": "2025-04-03T09:23:39.211832Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.198174Z",
          "shell.execute_reply": "2025-04-03T09:23:39.21112Z"
        },
        "trusted": true,
        "id": "-OakBgJn_nXV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "# Load VGG19 and inspect the architecture\n",
        "vgg19_model = models.vgg19(weights=models.VGG19_Weights.DEFAULT)\n",
        "\n",
        "# Print out the model to see the layers\n",
        "print(vgg19_model.features)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:39.212763Z",
          "iopub.execute_input": "2025-04-03T09:23:39.213059Z",
          "iopub.status.idle": "2025-04-03T09:23:44.45883Z",
          "shell.execute_reply.started": "2025-04-03T09:23:39.213Z",
          "shell.execute_reply": "2025-04-03T09:23:44.457779Z"
        },
        "id": "ldSjWbJu_nXW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Perceptual Loss\n",
        "#  Need to modify this for vgg19\n",
        "\n",
        "class PerceptualLoss(nn.Module):\n",
        "    # def __init__(self, feature_layers=[0, 5, 10, 19, 28], weights=[1.0]*5):\n",
        "    def __init__(self, feature_layers=[0, 5, 10, 14, 19], weights=[1.0]*5):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        vgg_weights = VGG19_Weights.DEFAULT\n",
        "        self.vgg = vgg19(weights=vgg_weights).features[:max(feature_layers)+1].to(device).eval()\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.feature_layers = feature_layers\n",
        "        self.weights = weights\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        # Since the predicted and target images are ab channels, we need to create 3-channel images\n",
        "        # We'll concatenate the L channel with the ab channels to form Lab images, then convert to RGB\n",
        "        # For perceptual loss, we need RGB images with 3 channels\n",
        "\n",
        "        # Reconstruct Lab images\n",
        "        L = torch.zeros_like(pred[:, :1, :, :]).to(device)  # Dummy L channel\n",
        "        pred_lab = torch.cat([L, pred], dim=1)\n",
        "        target_lab = torch.cat([L, target], dim=1)\n",
        "\n",
        "        # Convert Lab to RGB\n",
        "        pred_rgb = lab_to_rgb(L, pred)\n",
        "        target_rgb = lab_to_rgb(L, target)\n",
        "\n",
        "        # Convert to tensors\n",
        "        pred_rgb = torch.from_numpy(pred_rgb).permute(0, 3, 1, 2).to(device).float()\n",
        "        target_rgb = torch.from_numpy(target_rgb).permute(0, 3, 1, 2).to(device).float()\n",
        "\n",
        "        # Normalize RGB images to [-1, 1]\n",
        "        pred_rgb = (pred_rgb / 0.5) - 1.0\n",
        "        target_rgb = (target_rgb / 0.5) - 1.0\n",
        "\n",
        "        loss = 0.0\n",
        "        x = pred_rgb\n",
        "        y = target_rgb\n",
        "        for i, layer in enumerate(self.vgg):\n",
        "            x = layer(x)\n",
        "            y = layer(y)\n",
        "            if i in self.feature_layers:\n",
        "                loss += self.weights[self.feature_layers.index(i)] * nn.functional.l1_loss(x, y)\n",
        "        return loss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.460104Z",
          "iopub.execute_input": "2025-04-03T09:23:44.460433Z",
          "iopub.status.idle": "2025-04-03T09:23:44.472172Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.4604Z",
          "shell.execute_reply": "2025-04-03T09:23:44.470942Z"
        },
        "trusted": true,
        "id": "3udEBMqA_nXW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Model Initialization\n",
        "\n",
        "def init_weights(net, init='kaiming'):\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and ('Conv' in classname or 'Linear' in classname):\n",
        "            if init == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init == 'normal':\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=0.02)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "    net.apply(init_func)\n",
        "    return net\n",
        "\n",
        "def init_model(model):\n",
        "    model = model.to(device)\n",
        "    model = init_weights(model)\n",
        "    return model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.473493Z",
          "iopub.execute_input": "2025-04-03T09:23:44.473835Z",
          "iopub.status.idle": "2025-04-03T09:23:44.502408Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.473781Z",
          "shell.execute_reply": "2025-04-03T09:23:44.501347Z"
        },
        "trusted": true,
        "id": "L2FmXlJ5_nXX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: MainModel Class\n",
        "\n",
        "class MainModel(nn.Module):\n",
        "    def __init__(self, net_G=None, net_D=None, lr_G=2e-4, lr_D=2e-4,\n",
        "                 lambda_L1=100., lambda_perceptual=10.):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.lambda_L1 = lambda_L1\n",
        "        self.lambda_perceptual = lambda_perceptual\n",
        "\n",
        "        if net_G is None:\n",
        "            self.net_G = init_model(UnetGenerator(input_c=1, output_c=2))\n",
        "        else:\n",
        "            self.net_G = net_G.to(self.device)\n",
        "\n",
        "        if net_D is None:\n",
        "            self.net_D = init_model(PatchDiscriminatorSN(input_c=3))\n",
        "        else:\n",
        "            self.net_D = net_D.to(self.device)\n",
        "\n",
        "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
        "        self.L1criterion = nn.L1Loss()\n",
        "        self.perceptual_loss = PerceptualLoss()\n",
        "\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G,\n",
        "                                betas=(0.5, 0.999))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D,\n",
        "                                betas=(0.5, 0.999))\n",
        "\n",
        "    def setup_input(self, data):\n",
        "        self.L = data['L'].to(self.device)  # Input SAR image\n",
        "        self.ab = data['ab'].to(self.device)  # Ground truth ab channels\n",
        "\n",
        "    def forward(self):\n",
        "        self.fake_color = self.net_G(self.L)  # Generate fake ab channels\n",
        "\n",
        "    def backward_D(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)  # Concatenate L and fake ab\n",
        "        real_image = torch.cat([self.L, self.ab], dim=1)  # Concatenate L and real ab\n",
        "\n",
        "        fake_preds = self.net_D(fake_image.detach())\n",
        "        real_preds = self.net_D(real_image)\n",
        "\n",
        "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image)\n",
        "\n",
        "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G_perceptual = self.perceptual_loss(self.fake_color, self.ab) * self.lambda_perceptual\n",
        "\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1 + self.loss_G_perceptual\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize(self):\n",
        "        # Update Discriminator\n",
        "        self.forward()\n",
        "        self.net_D.train()\n",
        "        self.opt_D.zero_grad()\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "\n",
        "        # Update Generator\n",
        "        self.net_G.train()\n",
        "        self.opt_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.503678Z",
          "iopub.execute_input": "2025-04-03T09:23:44.504046Z",
          "iopub.status.idle": "2025-04-03T09:23:44.520671Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.503985Z",
          "shell.execute_reply": "2025-04-03T09:23:44.519753Z"
        },
        "trusted": true,
        "id": "SUgz1Rhk_nXY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Pretraining the Generator\n",
        "\n",
        "def pretrain_generator(net_G, train_dl, criterion, optimizer, epochs):\n",
        "    net_G.train()\n",
        "    for epoch in range(epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        for data in tqdm(train_dl):\n",
        "            L = data['L'].to(device)\n",
        "            ab = data['ab'].to(device)\n",
        "\n",
        "            preds = net_G(L)\n",
        "            loss = criterion(preds, ab)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_meter.update(loss.item(), L.size(0))\n",
        "\n",
        "        print(f\"Pretraining Epoch [{epoch+1}/{epochs}], Loss: {loss_meter.avg:.5f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.521772Z",
          "iopub.execute_input": "2025-04-03T09:23:44.522101Z",
          "iopub.status.idle": "2025-04-03T09:23:44.536367Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.522065Z",
          "shell.execute_reply": "2025-04-03T09:23:44.535398Z"
        },
        "trusted": true,
        "id": "eCm0VRKo_nXY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_model(model, train_dl, val_dl, epochs, pretrain_epochs=5, display_every=5):\n",
        "#     # Pretrain Generator\n",
        "#     print(\"Starting Generator Pretraining...\")\n",
        "#     pretrain_generator(\n",
        "#         net_G=model.module.net_G,\n",
        "#         train_dl=train_dl,\n",
        "#         criterion=model.module.L1criterion,\n",
        "#         optimizer=model.module.opt_G,\n",
        "#         epochs=pretrain_epochs\n",
        "#     )\n",
        "#     print(\"Pretraining Completed.\\n\")\n",
        "\n",
        "#     # Training with GAN\n",
        "#     for epoch in range(epochs):\n",
        "#         model.module.net_G.train()\n",
        "#         model.module.net_D.train()\n",
        "#         loss_meter_dict = {'loss_D': AverageMeter(), 'loss_G': AverageMeter()}\n",
        "#         for data in tqdm(train_dl):\n",
        "#             model.module.setup_input(data)\n",
        "#             model.module.optimize()\n",
        "\n",
        "#             # Update loss meters\n",
        "#             loss_meter_dict['loss_D'].update(model.module.loss_D.item(), data['L'].size(0))\n",
        "#             loss_meter_dict['loss_G'].update(model.module.loss_G.item(), data['L'].size(0))\n",
        "\n",
        "#         # Validation and Visualization\n",
        "#         if (epoch + 1) % display_every == 0:\n",
        "#             print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
        "#             print(f\"Loss_D: {loss_meter_dict['loss_D'].avg:.5f}, \"\n",
        "#                   f\"Loss_G: {loss_meter_dict['loss_G'].avg:.5f}\")\n",
        "#             data = next(iter(val_dl))\n",
        "#             visualize(model.module, data, save=True, epoch=epoch+1)\n",
        "#             torch.save(model.module.state_dict(), f'model_epoch_{epoch+1}.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.537399Z",
          "iopub.execute_input": "2025-04-03T09:23:44.537715Z",
          "iopub.status.idle": "2025-04-03T09:23:44.550674Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.537681Z",
          "shell.execute_reply": "2025-04-03T09:23:44.549837Z"
        },
        "trusted": true,
        "id": "pOFfbwy4_nXY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dl, val_dl, epochs, pretrain_epochs=5, display_every=5):\n",
        "    # Pretrain Generator\n",
        "    print(\"Starting Generator Pretraining...\")\n",
        "    pretrain_generator(\n",
        "        net_G=model.module.net_G,\n",
        "        train_dl=train_dl,\n",
        "        criterion=model.module.L1criterion,\n",
        "        optimizer=model.module.opt_G,\n",
        "        epochs=pretrain_epochs\n",
        "    )\n",
        "    print(\"Pretraining Completed.\\n\")\n",
        "\n",
        "    # Training with GAN\n",
        "    for epoch in range(epochs):\n",
        "        model.module.net_G.train()\n",
        "        model.module.net_D.train()\n",
        "        loss_meter_dict = {'loss_D': AverageMeter(), 'loss_G': AverageMeter(), 'per_pixel_acc': AverageMeter()}  # Added per-pixel accuracy\n",
        "\n",
        "        for data in tqdm(train_dl):\n",
        "            model.module.setup_input(data)\n",
        "            model.module.optimize()\n",
        "\n",
        "            # Update loss meters\n",
        "            loss_meter_dict['loss_D'].update(model.module.loss_D.item(), data['L'].size(0))\n",
        "            loss_meter_dict['loss_G'].update(model.module.loss_G.item(), data['L'].size(0))\n",
        "\n",
        "        # Validation and Per-Pixel Accuracy Calculation\n",
        "        if (epoch + 1) % display_every == 0:\n",
        "            model.module.net_G.eval()\n",
        "            with torch.no_grad():\n",
        "                val_data = next(iter(val_dl))\n",
        "                L = val_data['L'].to(device)\n",
        "                ab_gt = val_data['ab'].to(device)\n",
        "\n",
        "                ab_pred = model.module.net_G(L)  # Get predictions\n",
        "\n",
        "                # Compute per-pixel accuracy\n",
        "                threshold = 0.05  # Define tolerance for color difference\n",
        "                correct_pixels = torch.abs(ab_pred - ab_gt) < threshold\n",
        "                per_pixel_accuracy = correct_pixels.float().mean().item()\n",
        "\n",
        "                loss_meter_dict['per_pixel_acc'].update(per_pixel_accuracy, L.size(0))\n",
        "\n",
        "            # Print losses and accuracy\n",
        "            print(f\"\\nEpoch [{epoch+1}/{epochs}]\")\n",
        "            print(f\"Loss_D: {loss_meter_dict['loss_D'].avg:.5f}, \"\n",
        "                  f\"Loss_G: {loss_meter_dict['loss_G'].avg:.5f}, \"\n",
        "                  f\"Per-Pixel Accuracy: {loss_meter_dict['per_pixel_acc'].avg:.5f}\")\n",
        "\n",
        "            # Save Model and Visualize\n",
        "            visualize(model.module, val_data, save=True, epoch=epoch+1)\n",
        "            torch.save(model.module.state_dict(), f'model_epoch_{epoch+1}.pth')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.552102Z",
          "iopub.execute_input": "2025-04-03T09:23:44.552412Z",
          "iopub.status.idle": "2025-04-03T09:23:44.569853Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.552378Z",
          "shell.execute_reply": "2025-04-03T09:23:44.568848Z"
        },
        "id": "Ye1Uc4ee_nXZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = MainModel()\n",
        "\n",
        "# Wrap the model with DataParallel\n",
        "model = nn.DataParallel(model)\n",
        "\n",
        "# Training parameters\n",
        "pretrain_epochs = 5\n",
        "gan_epochs = 20\n",
        "total_epochs = gan_epochs\n",
        "\n",
        "# Start training\n",
        "train_model(\n",
        "    model=model,\n",
        "    train_dl=train_dl,\n",
        "    val_dl=val_dl,\n",
        "    epochs=total_epochs,\n",
        "    pretrain_epochs=pretrain_epochs,\n",
        "    display_every=5\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-03T09:23:44.570891Z",
          "iopub.execute_input": "2025-04-03T09:23:44.571213Z",
          "iopub.status.idle": "2025-04-03T12:52:06.177155Z",
          "shell.execute_reply.started": "2025-04-03T09:23:44.571179Z",
          "shell.execute_reply": "2025-04-03T12:52:06.176077Z"
        },
        "trusted": true,
        "id": "7wZRI6Og_nXZ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}